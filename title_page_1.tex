
\documentclass[12pt]{article}
\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{caption}
\usepackage{float}
\usepackage{subfig}
\usepackage{comment}
\usepackage{subcaption}
\usepackage{listings}
\usepackage{indentfirst}
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}
 \usepackage{tikz}
\usepackage{enumitem}
\usetikzlibrary{trees}
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
\lstset{style=mystyle}
\usepackage{titlesec}
\titleformat{\paragraph}
{\normalfont\normalsize\bfseries}{\theparagraph}{1em}{}
\titlespacing*{\paragraph}
{0pt}{3.25ex plus 1ex minus .2ex}{1.5ex plus .2ex}
\begin{document}


\begin{titlepage}


\newcommand{\HRule}{\rule{\linewidth}{0.5mm}} % Defines a new command for the horizontal lines, change thickness here

\center % Center everything on the page
 
%----------------------------------------------------------------------------------------
%	HEADING SECTIONS
%----------------------------------------------------------------------------------------

\textsc{\LARGE Universidade de Aveiro}\\[1.5cm] % Name of your university/college
\textsc{\Large IEETA}\\[0.5cm] % Major heading such as course name
\textsc{\Large RETIOT}\\[0.5cm]

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\HRule \\[0.4cm]
{ \huge \bfseries Technical Report}\\[0.4cm] % Title of your document
\HRule \\[1.5cm]
 
%----------------------------------------------------------------------------------------
%	AUTHOR SECTION
%----------------------------------------------------------------------------------------

\begin{minipage}{0.4\textwidth}
\begin{flushleft} \large
Francisco Santos % Your name
\end{flushleft}
\end{minipage}
~
\begin{minipage}{0.4\textwidth}
\begin{flushright} \large
Nº76618\\
\end{flushright}
\end{minipage}\\[2cm]

% If you don't want a supervisor, uncomment the two lines below and remove the section above
\Large {RETIOT -}
%John \textsc{Smith}\\[3cm] % Your name

%----------------------------------------------------------------------------------------
%	DATE SECTION
%----------------------------------------------------------------------------------------

{\large \emph{February de 2018}}\\[2cm] % Date, change the \today to a set date if you want to be precise

%----------------------------------------------------------------------------------------
%	LOGO SECTION
%----------------------------------------------------------------------------------------

\includegraphics[scale=0.4]{ua_logo.png} % Include a department/university logo - this will require the graphicx package
 
%----------------------------------------------------------------------------------------

\vfill % Fill the rest of the page with whitespace

\end{titlepage}
%%\renewcommand{\figurename}{Figura}
%%\renewcommand{\tablename}{Tabela}
%%\renewcommand{\contentsname}{Conteúdo}
\tableofcontents
\newpage
%ROS BASICS
\section{ROS}

\subsection{What is ROS}
ROS or Robot Operating System is an open-source, meta-operating system that provides libraries and tools to help developers create robot applications. This includes hardware abstraction, device drivers, visualizers, message-passing, package management and more.
\subsection{ROS basics}
In a graphic level, ROS is composed by:
\begin{itemize}
\item \textbf{Nodes} - Processes that perform computation.
\item \textbf{Messages} - ROS data type used when subscribing or publishing in a topic. 
\item \textbf{Topics} - Nodes can send messages by publishing to a topic or receive them by subscribing to a topic. 
\item \textbf{Master} - Provides registration of names (helps nodes find each other).
\item \textbf{rosout} - ROS equivalent of stdout 
\item \textbf{roscore} - Master+rosout+parameter server. 
\end{itemize}
%%\subsubsection{ROS nodes}
%%\subsubsection{ROS topics}
%%\subsubsection{ROS subscribers and publishers}
%%REVER ISTO
Figure \ref{fig:ros_concepts} shows the general architecture of ROS.

\begin{figure}[!htb]
    \centering
    \includegraphics[scale=0.25]{ros_graph.png}
    \caption{ROS Graph Concepts}
    \label{fig:ros_concepts}
\end{figure}
\section{interface between ROS and the radar}
Texas Instruments provides a ros package that interfaces radar data to the ROS message format.
To do this it loads two nodelets:
\begin{itemize}
\item \textbf{mmWaveCommSrv} - Provides the mmWave UART Command Line Interface as a ROS Service. \textbf{mmWaveQuickConfig} node uses this service to load a full .cfg file to the EVM.
\item \textbf{mmWaveDataHdl} - This nodelet reads and sorts the incoming radar data from the mmWave EVM. Publishes the output as a PointCloud2 type ROS message to the topic \textbf{/radar/RScan}.
\end{itemize}

Finnaly we have the \textbf{mmWaveQuickConfig} node that will read a user specified radar chirp profile (.cfg file) line-by-line and send each line to the \textbf{mmWaveCommSrv} nodelet to configure the EVM.
%%DEMO DATA STRUCTURE -> ROS POINTCLOUD
%% ROS POINTCLOUD -> PCL POINTCLOUD
\
\subsection{PointCloud2 data stucture}

%%PUT figure:
The published ROS message PointCloud2 follows the mmwave demo structure (Fig. 2). Each point has 6 fields:
\begin{itemize}
\item x - position x of the object detected relative to the radar frame.
\item y - position y.
\item z - position z (for AWR1642 this is equal to zero).
\item intensity - relative power of the received signal corresponding to that object.
\item range - range of the object relative to the radar frame.
\item doppler - radial velocity of the object relative to the radar frame.
\end{itemize}
\begin{figure}[!htb]
    \centering
    \includegraphics[scale=0.7]{2_demo_vis_struct.PNG}
    \caption{Part of the mmwave demo packet containing object detection information. This fields will be used to construct the ROS PointCloud2.}
    \label{fig:my_label}
\end{figure}
\subsubsection{Running the driver and visualizing the outputted PointCloud2}
We can visualize the published PointCloud2 message using rviz by following this steps:
\begin{enumerate}
    \item Create your ROS workspace.
    %??? Anexo
    \item Install the serial ROS package and TI mmWave ROS Driver in that workspace.
    %??? Anexo
    \item  Finnaly, while in your workspace directory run the commands:
    \begin{lstlisting}[language=bash]
source devel/setup.bash
roslaunch ti_mmwave_rospkg rviz_1642_2d.launch
\end{lstlisting}
\end{enumerate}
This will launch the TI mmWave ROS Driver nodes that configure the EVM and publish the radar data. After that rviz will load and you should be able to visualize the objects detected by the radar. Figure \ref{fig:radar_rviz} shows an example of the radar data displayed on rviz. The points correspond to object detected by the radar.
\begin{figure}[!htb]
    \centering
    \includegraphics[scale=0.2]{pc_not_filt.png}
    \caption{Pointcloud2 radar data displayed by rviz}
    \label{fig:radar_rviz}
\end{figure}
\subsection{Visualization markers}´
Seeing the points in the XY space plane is not enough to fully visualize the radar data sent since each point also gives us velocity and intensity information.
We can visualize it by using markers such as arrows or text in rviz.
Figure \ref{fig:doppler_marker} displays the radial velocity of each point with an arrow. The size of the arrow indicates how fast the object is going. Figure \ref{fig:intensity_marker} shows the intensity values of each object in text. This type of visualization will be useful later on when we try to filter the cloud.

\begin{figure}[!htb]
    \centering
    \includegraphics[width=\linewidth]{doppler_marker.png}
    \caption{Arrow markers displaying the points radial velocity}
    \label{fig:doppler_marker}
\end{figure}

\begin{figure}[!htb]
    \centering
    \includegraphics[width=\linewidth]{intensity_marker.png}
    \caption{Text markers displaying the points intensity values}
    \label{fig:intensity_marker}
\end{figure}
\subsection{Chirp profile configuration file}
The characteristics of this point cloud such as publishing rate, range resolution, maximum range, velocity resolution, maximum velocity depends on the chirp profile configuration file loaded in the EVM. This file is located in the \textbf{"cfg"} folder of the ti mmwave package and can be replaced in order to accommodate a given application.

The easiest way to create a chirp configuration file is the mmWave Demo Visualizer. This will auto generate a configuration file given a set of specifications.
Another way of doing this is manually. This however requires the understanding of the radar operating principle and the meaning of the commands in the configuration file.
%??????????????
For more information on this topics we suggest the reading of the links bellow:
%SDK USER GUIDE
%CHIRP PARAMETER CONFIG

\section{Point Cloud Manipulation}
Now that we have the radar constantly giving us a point cloud we can further process using the \textbf{Point Cloud Library}. PCL offers a wide variety of modules to handle point clouds. In our case we will use it for filtering, clustering and other operations.
\subsection{Passthrough Filters}
In our point cloud there may be some points that have characteristics we don't want, such as points with intensity too low that lead to false detections, or points too far away from the radar. To remove this points we use \textbf{passthrough} filters that specify the range of values a given channel can have in order for a point to be kept in the point cloud. 

For example, if we are only interested in obstacles that are moving between 0.5 m/s and 1.0 m/s (radial velocity), this can be done by using a pass through filter on the doppler channel.
Figure \ref{fig:filters} shows an example where we delete false detections close to the radar by filtering the pointcloud by intensity.
\begin{figure}[h]%
    \centering
    \subfloat[Non filtered pointcloud]{\includegraphics[width=6.34cm]{not_filt.png} }%
    \qquad
    \subfloat[Filtered pointcloud by intensity]{{\includegraphics[width=6.34cm]{filt.png}}}%
    \caption{Example of filtering the pointcloud}%
    \label{fig:filters}
\end{figure}

%%PUT IMAGE INTENSITY FILTERING  RVIZ
\subsection{Euclidean Clustering}
If we want to identify some relatively large objects such as persons we can use euclidean clustering. This identifies a subset of points that are close together. The two main parameters in this operation are:
\begin{itemize}
\item \textbf{minClusterSize} - Minimum number of points a cluster must have in order to be valid.
\item \textbf{ClusterTolerance}  - Maximum distance a point may have to a cluster member to also be counted as member of that cluster.
\end{itemize}
%%%PUT CLUSTER RVIZ FIGURE
This parameters must be tuned to the type of cluster we want to find. 
If the \textbf{ClusterTolerance} parameter is too small, it can happen that an actual object can be seen as multiple clusters, if you set the value too high, it could happen, that multiple objects are seen as one cluster.
In figure \ref{fig:filters} we use the module pcl
%% CLUSTER FIGURE
\begin{figure}[!htb]
    \centering
    \includegraphics[width=\linewidth]{cluster.png}
    \caption{Clustering}
    \label{fig:clustering}
\end{figure}
\subsection{Using radar velocity information to predict cluster movement}
We previously said that our point cloud has a doppler channel that retrieves the relative radial velocity of the point in respect to the radar. We can use this information to compute the mean velocity of a cluster and make a prediction of its position in the future. This comes with the limitation that the radar only gives us radial velocity so the prediction will just estimate if the cluster will be closer or further away. However this information might be useful for avoiding collisions with moving objects when navigating with a robot.
%%PUT IMAGE OF PREDICTED PC2
This information may be useful to avoid collisions when the robot is navigating. 
With the clusters identified we can now estimate its mean velocity and with that try to predict its position in the future. 
\section{ROS Navigation Stack}

The ROS navigation stack is a set of software packages that properly combined can get a robot to navigate autonomously.
Figure X  shows an example of turtlebot2 using the navigation stack to drive in rviz.
However, before running it we first need to properly setup the robot.
\subsection{Requirements}
\subsubsection{Transform Configuration}
The Navigation stack requires that the relationships between the different frames must be published in \textbf{tf}, for example the transform of a sensor frame relative to the  base\_link frame. This makes it so the robot perceives what is around him correctly which is crucial in navigation.
Figure \ref{fig:tf} shows all the frames and their transforms with each other. However the main transforms we need to worry about is the sensor frames relative to the center of the robot.
\begin{figure}[!htb]
    \centering
    \includegraphics[scale=0.25]{tf.png}
    \caption{Transform relationships in our robot}
    \label{fig:tf}
\end{figure}
\subsubsection{Sensor sources}
To avoid obstacles we need some type of sensors that can detect them. Before running the stack we need to make sure they are publishing this information in the \textbf{PointCloud2} or \textbf{LaserScan} ROS message format. In our case we will use both the \textbf{radar} (PointCloud2) and the \textbf{laser} (LaserScan) connected to our turtlebot as our observation sources.
Figure \ref{fig:sensors} shows an example of the published data from both of them in rviz.
\begin{figure}[!htb]
    \centering
    \includegraphics[scale=0.4]{sensors2.png}
    \caption{Obstacle defections by both radar and lidar}
    \label{fig:sensors}
\end{figure}
\subsubsection{Odometry}
We need to localize the robot in some way to correctly navigate. Therefore we require a topic that publishes odometry information.
%%AMCL
\subsubsection{Base Controller}
This node will subscribe to the velocity message outputted by the navigation stack and convert them into the appropriate motor commands to send to the mobile base that will actually make the robot move.

\subsubsection{Mapping}
This part is not mandatory but it helps to have a some sort of map being published to use as a global reference for the robot. Used by amcl and by the static layer of the global costmap.
\begin{figure}[!htb]
    \centering
    \includegraphics[scale=0.3]{map.png}
    \caption{Clustering}
    \label{fig:my_label}
\end{figure}


If the setup is done correctly we can now run the navigation stack.
\subsection{Navigation Stack components}
%%STUFF
Now that we have all the things we need for navigation we need an entity that actually processes all this information in an intelligent way to determine the best velocity command for the robot. This is done by the \textbf{move\_base node} and its peripherals.
Figure \ref{fig:plans} shows an example of the global and local plan calculated by the ROS navigation stack.
\begin{figure}[!htb]
    \centering
    \includegraphics[width=\linewidth]{rviz_navigation2.png}
    \caption{Global and Local plan calculated by the navigation stack}
    \label{fig:plans}
\end{figure}
\subsubsection{Move Base}

The move base node base links together a global and local planner as well as a local and global costmap to achieve the end goal provided by an action server. It also loads a set of determined recovery behaviors if the planners fail to produce a valid path. 

The global and local planners are plugins specified by the user. This choice will affect the behavior of the robot depending on the planners architecture and parameters. 
%%NAV STACK IMG
\begin{figure}[!htb]
    \centering
    \includegraphics[width=\linewidth]{overview_tf.png}
    \caption{Clustering}
    \label{fig:my_label}
\end{figure}
\paragraph{Main Parameters}
\begin{itemize}[label={}]
    \item \textbf{Controller frequency} - Frequency at which move base will ask the local planner for velocity commands (It will immediately publish this command which will make the robot move accordingly).
    %Does more stuff
    \item \textbf{Planner frequency} - Frequency at which the move base will ask the global planner for a new plan.
    \item \textbf{Planner patience} - Maximum amount of time to get a valid plan before going to recovery behavior (only if its in PLANNING state).
\end{itemize}

\subsubsection{Global Planner}
The job of this component is to produce the best trajectory for a robot to take with limited amount of information given by the global costmap. This plan can be updated when the robot gets stuck or by a user specific frequency. The algorithms used to get this path are usually \textbf{dijaktra} or \textbf{A*}. 
%%DJAKTRA AND A* global plan image
%%RVIZ image
\subsubsection{Local Planner}
The local planner takes into account the trajectory given by the global planner and tries to follow it. However the path given may be to close to an obstacle detected and in order to avoid it we must deviate from the plan given to avoid collision. The function of the local planner is to avoid dynamic obstacles that appear while still trying to follow the global plan and goal. 

It is encharged of computing the velocity that will be sent to the mobile base. To do this it simulates various trajectories and picks the best one.

\paragraph{Getting the Best Trajectory}

The algorithm to get the best trajectory goes as follows:
\begin{enumerate}
    \item Discreetly sample the velocity space(dx and dtheta)
    \[(dx,dtheta)=(max\_velocity-min\_velocity)/nsamples)\]
    \item For each sampled velocity predict its trajectory in a given time frame (\textbf{sim\_time}).
    \item Evaluate the cost of each trajectory  by using the value cost function
    \item Pick the one with lowest cost and publish the associated velocity.
    \item Repeat for a given rate (\textbf{controller\_frequency})
\end{enumerate}
%%SIMULATION IMAGE


\paragraph{Cost Function}
The cost function used to evaluate a trajectory is given by:
\[
       cost = 
  pdist\_scale * path\_dist
  + gdist\_scale * goal\_dist
  + occdist\_scale * maxobscost 
\]
Where \textbf{path\_dist} is the distance from the endpoint of the trajectory to the global path in map cells or meters, \textbf{goal\_dist} is the distance from the endpoint of the trajectory to the local goal in map cells or meters and \textbf{maxobscost} is equal to the \textbf{maximum obstacle cost} (given by the local costmap) along the trajectory .
%%RVIZ cost cloud
\begin{figure}[!htb]
    \centering
    \includegraphics[scale=0.3]{cost_cloud.png}
    \caption{Clustering}
    \label{fig:my_label}
\end{figure}
\subsubsection{Local and Global Costmap}
The global and local costmap share the same class, the  Costmap2DROS this class consists of a layered costmap that has takes into to account various layers defined by the user.

\paragraph{Available Layers}
\begin{itemize}[label={}]
    \item \textbf{Obstacle Layer} - Marks objects retrieved from observation\_sources with lethal value. It also raytraces observations to clear space (marks as free space cells that are within a raytrace line of an obstacle detected).
    %Does more stuff
    \item \textbf{Inflation Layer} - Inflates the detected obstacles. (needs explanation)
    %%....
    \item \textbf{Static Layer} - Retrieves static information from the /map topic and marks them has lethal objects (Obstacle layer may overwrite this layer).
\end{itemize}
Figure \ref{fig:layers} shows how the combined layers produce the master costmap that will be used by the planners.
\begin{figure}[!htb]
    \centering
    \includegraphics{layers.png}
    \caption{Clustering}
    \label{fig:layers}
\end{figure}
All the user defined layers will in conjunction create the final master costmap that will be used by the planners.

\subsection{Results}
\begin{comment}
%%RVIZ costmap
\*
\section{Using the radar for autonomous navigation of the turtlebot}

\subsection{ROS Navigation stack setup}

The ROS navigation package offers a reliable way for a robot to navigate alone. In order to  do this it needs a sensor source to detect obstacles, a reliable source of odometry and optionally a mused . The map is used as global reference to the robot.
%%IMAGEM ROS NAVIGATION STACK
\subsubsection{ROS Navigation structure}
\begin{tikzpicture}[sibling distance=10em,
  every node/.style = {shape=rectangle, sharp corners,
    draw, align=center,
    top color=blue!20, bottom color=blue!20}]]
  \node {Formulas}
    child { node {single-line} }
    child { node {multi-line}
      child { node {aligned at}
        child { node {relation sign} }
        child { node {several places} }
        child { node {center} } }
      child { node {first left,\\centered,\\last right} } };
\end{tikzpicture}

In this case we will use the radar pointcloud and the lidar laserscan as sensor sources and amcl for localization.
\subsection{Results}


%RADAR CONCEPTS
\section{Radar basics}
In order to retrieve the best data for our application we first need to understand how the radar works. The following sections will try explain how the radar calculates the range, velocity and angle of an object.
\subsection{range Detection}
An FMCW radar transmits a signal called a “chirp”. A chirp is a sinusoid whose frequency  increases linearly with time.
%% put A t and f t plot
A chirp is characterized by a start frequency (fc), bandwidth(B) and duration (Tc). The slope (S) of the chirp is the rate at witch the frequency of the chirp increases and is given by:
\begin{equation}
    S=\frac{B}{T_c}
\end{equation}
%%PUT SOME TEXT
Object detection follows this steps:
\begin{enumerate}
    \item The chirp is transmitted by the TX antenna
    \item The chirp is reflected off an object and the reflected chirp is received at the RX antenna
    \item The RX signal and TX signal are ‘mixed’ and the resulting signal is called an ‘IF signal’
\end{enumerate}


%%PUT IMAGE
%%%When the transmitted chirp encounters an object it will reflect back to the radar and will be captured by the RX antenna.
The RX signal is a sum of delayed versions of the TX signal. This means that the resulting IF signal will be a combination of sinusoids. Each of this correspond to a reflection of an object. For object $i$ the corresponding frequency $f_i$ is equal to:
\begin{equation}
    f_i=S\tau_i
\end{equation}
Where $\tau_i$ is equal to the round trip delay of the wave and is equal to:
\begin{equation}
    \tau_i=\frac{2d_i}{c}
\end{equation}
Where $d_i$ corresponds to the distance of the object to the radar and $c$ the speed of light.
%% PUT image
Putting this together the distance of object $i$ is given by:
\begin{equation}
    d_i=\frac{f_ic}{2S}
\end{equation}
\subsection{range resolution}
\subsection{velocity Detection}
\subsection{angle Detection}

 %A cluster is just a subset of points of the cloud that are close together. This takes into account if a point has alot of close neighbours. If it has than it is considered a cluster.  
 \begin{figure}[!htb]
    \centering
    \includegraphics[width=\linewidth]{local_plan.png}
    \caption{Clustering}
    \label{fig:my_label}
\end{figure}
\end{comment}
\end{document}